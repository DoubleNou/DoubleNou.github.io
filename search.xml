<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[生动的一次TCP3次握手和4次挥手]]></title>
    <url>%2F2019%2F04%2F26%2F%E7%94%9F%E5%8A%A8%E7%9A%84%E4%B8%80%E6%AC%A1TCP3%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C4%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[前言TCP握手挥手过程很简单，并不复杂。问题是记了忘，忘了记。以此循环，地老天荒。本渣还是决定用简单的描述手码一遍握手挥手的过程。 师弟师妹们也可以清楚一下零散的知识点。TCP三次握手TCP三次握手就好比两个人在街上隔着一条大街互相瞅了一眼（别担心，这就是发生在东北），但是因为天儿不好，这俩人不能确定是否是心里的那个他，没法直接交手。只能尴尬的先招手确定下对方是否认识自己。重点来了！！！刘能首先向赵四招手（syn），赵四看到刘能向自己招手，嘴角撇了撇。刘能看到赵四嘴角撇了，确认了赵四成功辨认出了自己(进入estalished状态)。但是赵四还有点狐疑，向四周看了一看，有没有可能刘能是在看别人呢，他也需要确认一下。所以赵四也向刘能招了招手(syn)，刘能看到赵四向自己招手后知道对方是在寻求自己的确认，于是也学着嘴角撇了撇(ack)，赵四看到对方的撇嘴后确认了刘能就是在向自己打招呼(进入established状态)。于是俩人加快步伐，走到了一起，相互拥抱，互喊“亲家！！！”。我们看到这个过程中一共是四个动作，刘能招手–赵四撇嘴–赵四招手–刘能撇嘴。其中赵四连续进行了2个动作，先是撇嘴(回复对方)，然后再次招手(寻求确认)，实际上可以将这两个动作合一，招手的同时撇嘴(syn+ack)。于是四个动作就简化成了三个动作，刘能招手–赵四撇嘴并招手–刘能撇嘴。这就是三次握手的本质，中间的一次动作是两个动作的合并。我们看到有两个中间状态，synsent和synrcvd，这两个状态叫着「半打开」状态，就是向对方招手了，但是还没来得及看到对方的撇嘴。synsent是主动打开方的「半打开」状态，synrcvd是被动打开方的「半打开」状态。客户端是主动打开方，服务器是被动打开方。 syn_sent: syn package has been sent syn_rcvd: syn package has been receivedTCP传输TCP 数据传输就是两个人隔空对话，差了一点距离，所以需要对方反复确认听见了自己的话。刘能喊了一句话(data)，赵四听见了之后要向刘能回复自己听见了(ack)。如果刘能喊了一句，半天没听到赵四回复，刘能就认为自己的话被大风吹走了，赵四没听见，所以需要重新喊话，这就是tcp重传。也有可能是赵四听到了刘能的话，但是赵四向刘能的回复被大风吹走了，以至于刘能没听见赵四的回复。刘能并不能判断究竟是自己的话被大风吹走了还是赵四的回复被大风吹走了，刘能也不用管，重传一下就是。 既然会重传，赵四就有可能同一句话听见了两次，这就是「去重」。「重传」和「去重」工作操作系统的网络内核模块都已经帮我们处理好了，用户层是不用关心的。 刘能可以向赵四喊话，同样赵四也可以向刘能喊话，因为tcp链接是「双工的」，双方都可以主动发起数据传输。不过无论是哪方喊话，都需要收到对方的确认才能认为对方收到了自己的喊话。 刘能虽然磕巴但话多，一说连说了八句话，赵四说话也费劲，这时候赵四可以不用一句一句回复，而是连续听了这八句话之后，一起向对方回复说前面你说的八句话我都听见了，这就是批量ack。但是刘能也不能一次性说了太多话，赵四的脑子短时间可能无法消化太多，两人之间需要有协商好的合适的发送和接受速率，这个就是「TCP窗口大小」。 网络环境的数据交互同人类之间的对话还要复杂一些，它存在数据包乱序的现象。同一个来源发出来的不同数据包在「网际路由」上可能会走过不同的路径，最终达到同一个地方时，顺序就不一样了。操作系统的网络内核模块会负责对数据包进行排序，到用户层时顺序就已经完全一致了。TCP 四次挥手TCP断开链接的过程和建立链接的过程比较类似，只不过中间的两部并不总是会合成一步走，所以它分成了4个动作，刘能挥手(fin)——赵四伤感地撇嘴(ack)——赵四挥手(fin)——刘能伤感地撇嘴(ack)。 之所以中间的两个动作没有合并，是因为tcp存在「半关闭」状态，也就是单向关闭。刘能已经挥了手，可是人还没有走，只是不再说话，但是耳朵还是可以继续听，赵四呢继续喊话。等待赵四累了，也不再说话了，超刘能挥了挥手，刘能伤感地撇嘴了一下，才彻底结束了。上面有一个非常特殊的状态time_wait，它是主动关闭的一方在回复完对方的挥手后进入的一个长期状态，这个状态标准的持续时间是4分钟，4分钟后才会进入到closed状态，释放套接字资源。不过在具体实现上这个时间是可以调整的。 它就好比主动分手方要承担的责任，是你提出的要分手，你得付出代价。这个后果就是持续4分钟的time_wait状态，不能释放套接字资源(端口)，就好比守寡期，这段时间内套接字资源(端口)不得回收利用。 它的作用是重传最后一个ack报文，确保对方可以收到。因为如果对方没有收到ack的话，会重传fin报文，处于time_wait状态的套接字会立即向对方重发ack报文。 同时在这段时间内，该链接在对话期间于网际路由上产生的残留报文(因为路径过于崎岖，数据报文走的时间太长，重传的报文都收到了，原始报文还在路上)传过来时，都会被立即丢弃掉。4分钟的时间足以使得这些残留报文彻底消逝。不然当新的端口被重复利用时，这些残留报文可能会干扰新的链接。 4分钟就是2个MSL，每个MSL是2分钟。MSL就是maximium segment lifetime——最长报文寿命。这个时间是由官方RFC协议规定的。至于为什么是2个MSL而不是1个MSL，我还没有看到一个非常满意的解释。四次挥手也并不总是四次挥手，中间的两个动作有时候是可以合并一起进行的，这个时候就成了三次挥手，主动关闭方就会从finwait1状态直接进入到timewait状态，跳过了finwait_2状态。总结TCP状态转换是一个非常复杂的过程，本文仅对一些简单的基础知识点进行了类比讲解。关于TCP的更多知识还需要读者去搜寻相关技术文章进入深入学习。如果读者对TCP的基础知识掌握得比较牢固，高级的知识理解起来就不会太过于吃力。]]></content>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[破解数据库连接工具navicat（亲测可用）]]></title>
    <url>%2F2019%2F04%2F25%2F%E7%A0%B4%E8%A7%A3%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E5%B7%A5%E5%85%B7navicat%EF%BC%88%E4%BA%B2%E6%B5%8B%E5%8F%AF%E7%94%A8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[破解步骤下载1.最好下载Navicat Premium 12版本，至于mac 还是 win 自行选择。另外选择破解版本也要看下网上的介绍。本人用12版本已经够用了。生成秘钥对2.生成自己的RSA公钥私钥对 （这里直接使用大神的密钥，也可以自己生成测试可以用） 这步与windows版破解相同，可以用open ssl工具生成，也可以使用其他工具生成，注意密钥是2048位的，PKCS#8格式为了节省时间，可以使用我提供的一对密钥。公钥： —–BEGIN PUBLIC KEY—–MIIBITANBgkqhkiG9w0BAQEFAAOCAQ4AMIIBCQKCAQB8vXG0ImYhLHvHhpi5FS3gd2QhxSQiU6dQ04F1OHB0yRRQ3NXF5py2NNDw962i4WP1zpUOHh94/mg/KA8KHNJXHtQVLXMRms+chomsQCwkDi2jbgUa4jRFN/6N3QejJ42jHasY3MJfALcnHCY3KDEFh0N89FV4yGLyDLr+TLqpRecg9pkPnOp++UTSsxz/e0ONlPYrra/DiaBjsleAESZSI69sPD9xZRt+EciXVQfybI/2SYeAdXMm1B7tHCcFlOxeUgqYV03VEqiC0jVMwRCd+03NU3wvEmLBvGOmNGudocWIF/y3VOqyW1byXFLeZxl7s+Y/SthxOYXzu3mF+2/pAgMBAAE=—–END PUBLIC KEY—– 私钥： —–BEGIN RSA PRIVATE KEY—–MIIEogIBAAKCAQB8vXG0ImYhLHvHhpi5FS3gd2QhxSQiU6dQ04F1OHB0yRRQ3NXF5py2NNDw962i4WP1zpUOHh94/mg/KA8KHNJXHtQVLXMRms+chomsQCwkDi2jbgUa4jRFN/6N3QejJ42jHasY3MJfALcnHCY3KDEFh0N89FV4yGLyDLr+TLqpRecg9pkPnOp++UTSsxz/e0ONlPYrra/DiaBjsleAESZSI69sPD9xZRt+EciXVQfybI/2SYeAdXMm1B7tHCcFlOxeUgqYV03VEqiC0jVMwRCd+03NU3wvEmLBvGOmNGudocWIF/y3VOqyW1byXFLeZxl7s+Y/SthxOYXzu3mF+2/pAgMBAAECggEAK5qZbYt8wenn1uZg6onRwJ5bfUaJjApL+YAFx/ETtm83z9ByVbx4WWT7CNC7fK1nINy20/mJrOTZkgIxx6otiNC4+DIsACJqol+RLoo8I9pk77Ucybn65ZteOz7hVZIU+8j6LzW0KDt6yowXe75r7G/NEpfibNc3Zz81+oDd2x+bHyGbzc9QcePIVuEzkof6jgpbWrQZU14itx9lVxEgj/fbMccvBx8brR/l9ClmDZd9Y6TWsF1rfJpF3+DPeqFkKCiD7PGz3bs4O/ZdZrfV21ZNVusBW49G6bU63gQVKsOf1qGo3efbAW1HVxgTQ/lExVdcMvdenZm+ADKpL4/wUQKBgQDOfBjn3OC2IerUFu18EgCS7pSjTSibXw+TeX3D5zwszLC091G2rGlT5DihBUhMfesNdpoZynrs4YB6Sz9C3wSGAB8AM/tNvPhtSVtbMHmrdT2DEEKCvLkORNBnt+8aTu2hGRanw9aL1189gzwrmXK5ZuuURfgLrB9ihrvjo4VznQKBgQCapx13dEA1MwapBiIa3k8hVBCoGPsEPWqM33RBdUqUsP33f9/PCx00j/akwmjgQNnBlAJoY7LOqPCyiwOkEf40T4IlHdzYntWQQvHhfBwqSgdkTE9tKj43Ddr7JVFRL6yMSbW39qAp5UX/+VzOLGAlfzJ8CBnkXwGrnKPCVbnZvQKBgQCd+iof80jlcCu3GteVrjxMLkcAbb8cqG1FWpVTNe4/JFgqDHKzPVPUgG6nG2CGTWxxv4UFKHpGE/11E28SHYjbcOpHAH5LqsGy84X2za649JkcVmtclUFMXm/Ietxvl2WNdKF1t4rFMQFIEckOXnd8y/Z/Wcz+OTFF82l7L5ehrQKBgFXl9m7v6e3ijpN5LZ5A1jDL0Yicf2fmePUP9DGbZTZbbGR46SXFpY4ZXEQ9GyVbv9dOT1wN7DXvDeoNXpNVzxzdAIt/H7hN2I8NL+4vEjHG9n4WCJO4v9+yWWvfWWA/m5Y8JqusV1+N0iiQJ6T4btrE4JSVp1P6FSJtmWOKW/T9AoGAcMhPMCL+N+AvWcYt4Y4mhelvDG8e/Jj4U+lwS3g7YmuQuYx7h5tjrS33w4o20g/3XudPMJHhA3z+d8b3GaVM3ZtcRM3+Rvk+zSOcGSwn3yDy4NYlv9bdUj/4H+aU1Qu1ZYojFM1Gmbe4HeYDOzRsJ5BhNrrV12h27JWkiRJ4F/Q= —–END RSA PRIVATE KEY—–安装程序3 安装程序，并替换应用包内容目录中rpk文件的公钥 安装完毕后打开finder，找到应用程序，右键显示包内容，打开目录 /Contents/Resources，编辑rpk文件，将公钥替换并保存。算出有效的Mac版序列号密钥4 使用我算好的密钥可以跳过此步，继续第四步，节省时间。中文版64位密钥序列号： NAVH-T4PX-WT8W-QBL5 英文版64位密钥序列号： NAVG-UJ8Z-EVAP-JAUW解密请求码，生成激活码打开应用，断网！！！，点击注册，输入密钥 NAVH-T4PX-WT8W-QBL5，然后手动激活复制请求码，使用私钥解密请求码，得到激活码明文注意必须自己解密，因为解密后得到的“DI”是不同的激活码明文示例：{ “K” : “NAVHT4PXWT8WQBL5”, “P” : “Mac 10.13”, “DI” : “ODQ2Yjg2ZDBjMTEzMjhh”}在线RSA私钥解密：http://tool.chacuo.net/cryptrsaprikey 将得到的激活码明文进行修改，修改后格式如下{“K”:”NAVHT4PXWT8WQBL5”, “N”:”52pojie”, “O”:”52pojie.cn”, “DI”:”ODQ2Yjg2ZDBjMTEzMjhh”, “T”:1516939200}激活码明文格式最好复制我的，改变 “ “ 内的字符即可，在同一行哦，不要换行，否则激活失败！！！“K” “DI” 都替换成自己机器解密的信息，”N” “O” “T”自己定义 加密激活码明文，使用私钥加密激活码明文在线RSA私钥加密：http://tool.chacuo.net/cryptrsaprikey 复制加密后激活码信息到程序激活窗口，点击激活，即可成功激活完整教程贴图地址https://blog.csdn.net/xhd731568849/article/details/79751188]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rest微服务构建案例]]></title>
    <url>%2F2019%2F04%2F24%2FRest%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%84%E5%BB%BA%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[记住一句话：约定 &gt; 配置 &gt; 编码Rest微服务一个基础构建是整个微服务的一个基础，先说下总体介绍。 有以下几个部分： 1.mvc、mybatis（一带而过了） 2.maven（坐标、仓库、依赖、聚合、继承）。理论要熟练下。 maven的命令：maven -U clean package install 这是我常用的，也是在更新了包所必备去更新到本地的命令。其他工程才能依赖最新的jar包。 父工程包含很多子工程，子工程公用的依赖包可以提到父工程中。 撸码provider （一）构建父工程，分布式开发所必备的建工程流程。构建父工程要点就是maven 的打包packaging要为pom。goupId和artifactId都要起好，否则很容易混淆。 构建完pom父工程后，新构建的pom中有几大几个部分—- 1.头部(重要！)Other-&gt; Maven Moudle。goupId和artifactId都要起好还是一样的要起好，packaging这时侯 变了！变成了jar包。在构建框里面的置灰部分，你也会看见parent的工程也就是上方所说的父工程。点击确定！ 创建完毕后，返回头去父工程的pom文件中查看下，发现新增moudleName 构建实体类的样子记得最好用工具lombok （1）@AllArgsConstructor @NoArgsConstructor @Data @Accessors(chain = true) public class entity { private Long id; private String msg; private String DBSource; } （2）在yml中配置我们所需要的配置信息，例：mybatis、spring日志config、重要的是spring-application-name！！！！暴露出去的微服务名称。 （3）创建数据库genetator，自动生成mapper、entity、dao。 （4）给数据库造点假数据。对了，这里数据库的库和表要自己建好，否则（3）进行不下去。这一步省去了你很多时间，真正提高工作效率。如何运用，请看管理系统标签 （5）整合service层 （6）整合controller层 都在各层记得打@啊！！！ 添加主启动类：SpringApplication.run(所属类,args);启动！done consumer 构建consumer过程和上方大部分一致，直到（5）部，不再调用service层进行数据库操作了。 这里！！！！在controller中加入@Autowired RestTemplate restTemplate; 操作— restTemplate.getForObject();//传参3个参数，请求服务的URL（provider的controller地址），传递参数（provider api 对应参数），返回类型（可选boollean、有很多） restTemplate.postForObject();//同上 添加主启动类：SpringApplication.run(所属类,args);启动！done。实验下，发现consumer的调用直接调到了provider。 总结本期微服务的构建案例，总结其精髓就是rest api！同时也是和dubbo不同的所在。剩下搞过mvc开发的，熟悉其开发流程的同学来说，只是增添了一些小应用有没有，当然这些都是构建在SpringBoot的基础上搞的，SpringBoot这个框架，本人是真的喜欢，但是喜欢的同时千万要对其自动配置、起步依赖、Actuator、命令行界面要有深入理解。]]></content>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka的生产+消费]]></title>
    <url>%2F2019%2F04%2F23%2Fkafka%E7%9A%84%E7%94%9F%E4%BA%A7-%E6%B6%88%E8%B4%B9%2F</url>
    <content type="text"><![CDATA[消息队列的内容很丰富，目前我常用的是kafka，所以第一篇献给我的kafka，后续我们继续钻研下，RocketMQ、ActiveMQ。kafka的原生写法，不繁琐，直接看见配置项就👌，如果你是刚入门大数据或者是刚接手kafka的话难免有蒙圈的感觉，But！！！这不要紧，先蒙在其中，后续你接触多了大数据的东西，就会发现，很多组件用了很多的配置项，加载进配置项就可以用了。当然我说的还是比较原生的写法，刚刚写完了一遍HBase的原生，一时脱离不出底层的范围哈哈哈。 心灵鸡汤一下：刚入职的小白遇到不会的问题，甚者被批评，千万不要气馁，觉得自己不适合干这个。行业没有不适合的，只有干的开不开心。坚持一下没准你就有小骄傲了呢？废话少说，开始撸码生产者public class KafkaProvider{ private final Producer&lt;String, String&gt; producer; public final static String TOPIC = &quot;TEST-TOPIC&quot;; public KafkaProvider(){ Properties props = new Properties();//配置项！这行代码是kafka的源头。 props.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092&quot;);//zookeeper地址，集群用逗号分隔 //这里如果不熟悉的同学，可以看看kafa的架构图。每一个 ![](kafka架构.jpg) props.put(&quot;acks&quot;, &quot;all&quot;);//记录完整提交，最慢但是最大可能的持久化 props.put(&quot;retries&quot;, 3);//请求失败的重试次数 props.put(&quot;batch.size&quot;, 16384);//batch大小 props.put(&quot;linger.ms&quot;, 1);// 默认情况即使缓冲区有剩余的空间，也会立即发送请求，设置一段时间用来等待从而将缓冲区填的更多，单位为毫秒，producer发送数据会延迟1ms，可以减少发送到kafka服务器的请求数据 props.put(&quot;buffer.memory&quot;, 33554432);// 提供给生产者缓冲内存总量 props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);//写话方式 props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); //生成生产者 producer = new KafkaProducer&lt;String, String&gt;(props); } //在入口函数调用即可，具体应用情形根据项目实际来看 public void producer(){ int messageNo = 1; final int COUNT =1000; while (1){ String num = String.valueOf(messageNo); String data = &quot;hello kafka message:&quot; + num; ProducerRecord record = new ProducerRecord(TOPIC,data); producer.send(record); messageNo ++ ; System.out.println(messageNo); try { sleep(1000); } catch ( InterruptedException e ) { e.printStackTrace(); } } } }消费者public class KafkaConsumer { private final Consumer consumer ; public final static String TOPIC = “TEST-TOPIC”; private ExecutorService executors; public KafkaCon(){ Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092&quot;);//zk同生产者一致 props.put(&quot;group.id&quot;, &quot;2&quot;);//分组Id！！！！ props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);//自动提交，这是对offset的操作，有些需要对offset更加精准的处理，需要进行手动提交。 props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); consumer = new KafkaConsumer&lt;String, String&gt;(props); consumer.subscribe(Arrays.asList(TOPIC)); execute(10); } public void execute(int workerNum) { executors = new ThreadPoolExecutor(workerNum, workerNum, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue(1000), new ThreadPoolExecutor.CallerRunsPolicy()); Thread t = new Thread(new Runnable(){//启动一个子线程来监听kafka消息 @Override public void run(){ while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(200); for (final ConsumerRecord record : records) { System.out.println(&quot;【Kafka】监听到kafka的TOPIC【&quot; + record.topic() + &quot;】的消息&quot;); System.out.println(&quot;【Kafka】消息内容：&quot; + record.value()); executors.submit(new ConsumerWorker(record)); } } }}); t.start(); } } 这是标准的一个kafka配置信息，生产实战中的应用很简单，千万记住几个关键词：produce、consumer、topic、group.id、partition、broker，schema的含义，主要还是理解吧。提几个问题哈？如果你想多个消费者消费一个topic怎么办？partion中的消息是顺序的，多个partion间的消息呢？]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>消息队列，kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 代码请求URl样例]]></title>
    <url>%2F2019%2F04%2F23%2Fjava-%E4%BB%A3%E7%A0%81%E8%AF%B7%E6%B1%82URl%E6%A0%B7%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[习惯了在开发中运用工具（postman等）调试接口，几乎忘了用代码可以更好的处理实际情况。 Demo样例 /** * 发送post请求 * @param url 路径 * @param jsonObject 参数(json类型) * @param encoding 编码格式 * @return * @throws ParseException * @throws IOException */ public static String send(String url, JSONObject jsonObject,String encoding) throws ParseException, IOException{ String body = &quot;&quot;; //创建httpclient对象 CloseableHttpClient client = HttpClients.createDefault(); //创建post方式请求对象 HttpPost httpPost = new HttpPost(url); //装填参数 StringEntity s = new StringEntity(jsonObject.toString(), &quot;utf-8&quot;); //参数体有按要求也要进行Content-type赋值 s.setContentType(&quot;application/json&quot;); s.setContentEncoding(new BasicHeader(HTTP.CONTENT_TYPE, &quot;application/json&quot;)); //设置参数到请求对象中 httpPost.setEntity(s); System.out.println(&quot;请求地址：&quot;+url); // System.out.println(“请求参数：”+nvps.toString()); //设置header信息 //指定报文头【Content-type】、【User-Agent】选择其一就ok httpPost.setHeader(&quot;Content-type&quot;, &quot;application/x-www-form-urlencoded&quot;); httpPost.setHeader(&quot;Content-type&quot;, &quot;application/json&quot;); httpPost.setHeader(&quot;User-Agent&quot;, &quot;Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)&quot;); //执行请求操作，并拿到结果（同步阻塞） CloseableHttpResponse response = client.execute(httpPost); //获取结果实体 HttpEntity entity = response.getEntity(); if (entity != null) { //按指定编码转换结果实体为String类型 body = EntityUtils.toString(entity, encoding); } EntityUtils.consume(entity); //释放链接 response.close(); return body; }]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>Http</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot改造]]></title>
    <url>%2F2019%2F04%2F21%2FSpringBoot%E6%94%B9%E9%80%A0%2F</url>
    <content type="text"><![CDATA[刚入职的时候，发现我们接手项目是ssm和SpringBoot混用，这个”混用”听起来奇怪哈？一句话就是很多依赖项用了SpringBoot又用了原生，还用了ssm中的一些写法。直观看上去一句my god～～～对新入职的应届生来说，多少会有混淆，用起来也会很撇脚（碍手？）。但本菜狗认为这真是一个学习的好机会，从最原生的写一遍，写到SpringBoot，写到地老天荒。另外悄悄告诉你，我们的之前组件都是原生的哈哈哈哈，根本没有Compent，你知道怎么实现的吗？ 以上都是废话 干货 我介绍下SpringBoot的原理，也偷偷抓紧复习下。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>dubbo</tag>
        <tag>cloud</tag>
        <tag>kafka</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
</search>
